---
title: "Estado del Arte de la Investigación sobre técnicas de Aprendizaje profundo aplicado al monitoreo, detección y alerta temprana de floraciones de Cianobacterias y Cianotoxinas"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Comentarios

## Including Code

You can include R code in the document as follows:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


# Introducción

El presente informe describe la metodología utilizada para realizar el análisis del estado del arte de las investigaciones basadas en aprendizaje profundo para el monitoreo, detección y alerta temprana de floraciones de cianobacterias y cianotoxinas

## Contexto

Las floraciones de cianobacterias (FC) son eventos de crecimiento acelerado de cianobacterias en el agua, que pueden producir cianotoxinas, compuestos tóxicos para los seres humanos, animales y plantas. El monitoreo, detección y alerta temprana de FC son esenciales para la protección de la salud pública y el medio ambiente.

En los últimos años, el aprendizaje profundo (DL) ha sido aplicado con éxito al monitoreo, detección y alerta temprana de FC. DL es una rama de la inteligencia artificial (IA) que utiliza redes neuronales artificiales para aprender de datos sin supervisión.

## Metodología

Una de las técnicas más utilizadas para el análisis del estado del arte de las investigaciones basadas en DL para el monitoreo, detección y alerta temprana de FC es la minería de datos bibliográfica. La minería de datos bibliográfica es una disciplina que utiliza técnicas de aprendizaje automático para extraer conocimiento de los datos bibliográficos.

En este informe, se presentan las herramientas utilizadas para realizar el análisis del estado del arte de las investigaciones basadas en DL para el monitoreo, detección y alerta temprana de FC. Estas herramientas incluyen:

- R: Un lenguaje de programación para la estadística y el análisis de datos.
- RStudio: Un entorno de desarrollo integrado (IDE) para R
- Github: Un servicio de alojamiento de código fuente en la nube.
- R Markdown: Un formato de documento que permite combinar texto, código y resultados de análisis en un solo documento.

- OpenAlex: Una base de datos bibliográfica abierta de artículos científicos, que incluye millones de entidades interconectadas del sistema de investigación global, ofreciendo información sobre los autores, las instituciones, las revistas y los campos de investigación.
(Acceso al sitio oficial de OpenAlex)[https://openalex.org/] 
- OpenAlexR: Una biblioteca de R para acceder a OpenAlex y obtener registros bibliográficos.
(Acceso al Universo OpenAlex)[https://ropensci.r-universe.dev/openalexR]

- Bibliometrix: Un paquete R para la minería de datos bibliográficos.
(Aria, M. & Cuccurullo, C. (2017) bibliometrix: An R-tool for comprehensive science mapping analysis, Journal of Informetrics, 11(4), pp 959-975, Elsevier)[https://www.sciencedirect.com/science/article/abs/pii/S1751157717300500]


## Entorno de investigación

### Paquetes necesarios para montar las herramientas

Para montar las herramientas necesarias para realizar el análisis del estado del arte, se requiere lo siguiente:

- Un entorno de desarrollo con R instalado.
- Una cuenta de Github.
- RStudio instalado.
- Las bibliotecas OpenAlexR y Bibliometrix instaladas.

### Creación de un repositorio de Github

Para crear un repositorio de Github, se debe seguir el siguiente procedimiento:

- Ir al sitio web de Github.
- Hacer clic en el botón "Crear un repositorio".
- Ingresar un nombre para el repositorio y una descripción.
- Hacer clic en el botón "Crear".

### Creación de un archivo R Markdown

Para crear un archivo R Markdown, se debe seguir el siguiente procedimiento:

- Abrir RStudio.
- Seleccionar la pestaña "Archivo".
- Hacer clic en el botón "Nuevo documento".
- Seleccionar la opción "Archivo R Markdown".
- Guardar el archivo con la extensión ".Rmd".

### Instalación de las bibliotecas

Las bibliotecas OpenAlexR y Bibliometrix se pueden instalar con los siguientes comandos:

```{r bibliotecas, echo=FALSE}
install.packages("remotes")
remotes::install_github("ropensci/openalexR") ## Developer version de openalexR

repos_dev = c(CRAN = "https://cran.r-project.org/package=bibliometrix")
install.packages("Bibliometrix", repos=repos_dev)
```

# Ejemplo

A continuación, se presenta un ejemplo de cómo utilizar las técnicas descritas en este informe para realizar el análisis del estado del arte de las investigaciones basadas en DL para el monitoreo, detección y alerta temprana de FC.

1) En primer lugar, se cargan las bibliotecas necesarias:

```{r librerias, echo=FALSE}
options(openalexR.mailto = "example@email.com")
library(OpenAlexR)
library(Bibliometrix)
library(dplyr)
library(ggplot2)
```

2) Realizar una consulta y procesarla

2.1) Consultar utilizando funciones de openalexR

Objetivo: Descargar todos los **trabajos** que hayan sido **citados más de 50 veces**, **publicados entre 2020 y 2021**, que **incluyan las cadenas “deep learning” o “cyanobacteria” en el título, resumen o contenido** (este útlimo filtro se incluye si está disponible la indexación completa del artículo recuperado), **ordenandos por el total de citas en orden descendente**.

openalexR le ayuda a interactuar con la API OpenAlex para recuperar información bibliográfica sobre publicaciones, autores, lugares, instituciones y conceptos brindando 5 funciones principales:

+ oa_fetch: compone tres funciones a continuación para que el usuario pueda ejecutar todo en un solo paso, es decir, oa_query |> oa_request |> oa2df
+ oa_query: genera una consulta válida, escrita siguiendo la sintaxis de la API OpenAlex, a partir de un conjunto de argumentos proporcionados por el usuario.
+ oa_request: descarga una colección de entidades que coinciden con la consulta creada por oa_query o escrita manualmente por el usuario y devuelve un objeto JSON en formato de lista.
+ oa2df: convierte el objeto JSON en un tibble/marco de datos bibliográfico clásico.
+ oa_random: obtiene una entidad aleatoria, por ejemplo, oa_random("works") proporciona un trabajo diferente cada vez que lo ejecuta

```{r works_search, echo=FALSE}
works_search <- oa_fetch(
  entity = "works",
  search = c("deep learning", "cyanobacteria"),
  cited_by_count = ">50",
  from_publication_date = "2020-01-01",
  to_publication_date = "2021-12-31",
  options = list(sort = "cited_by_count:desc"),
  verbose = TRUE
)
```


2.1.1) Presentar los resultados en forma de tabla

```{r show_works, echo=FALSE}
works_search |>
  show_works() |>
  knitr::kable()
```


2.1.2) Analizar el resultado de la consulta utilizando n-gramas

N-grams: OpenAlex ofrece acceso (limitado) a los N-gramas del texto completo de las entidades de tipo works. Dado un vector de IDs de entidades de tipo works, **oa_ngrams** devuelve un dataframe de N-gramas (en la columna de lista de ngrams) para cada trabajo.

A continuación, se consultan los n-gramas de los trabajos recuperados con la consulta.

```{r ngrams_data, echo=FALSE}
works_identifier <- works_search$id

ngrams_data <- oa_ngrams(
  works_identifier = works_identifier,
  verbose = TRUE
)
```

2.1.3) Presentar los resultados en forma de tabla

```{r show_works, echo=FALSE}
ngrams_data |>
  knitr::kable()
```


2.1.4) Presentar los resultados en forma de tabla

```{r lapply_ngrams_data, echo=FALSE}
lapply(ngrams_data$ngrams, head, 3) |>
  knitr::kable()
```

2.1.5) Presentar los resultados en forma de gráficos

```{r ggplot_ngrams_data, echo=FALSE}
ngrams_data |>
  tidyr::unnest(ngrams) |>
  filter(ngram_tokens == 2) |>
  select(id, ngram, ngram_count) |>
  group_by(id) |>
  slice_max(ngram_count, n = 10, with_ties = FALSE) |>
  ggplot(aes(ngram_count, forcats::fct_reorder(ngram, ngram_count))) +
  geom_col(aes(fill = id), show.legend = FALSE) +
  facet_wrap(~id, scales = "free_y") +
  labs(
    title = "Top 10 fulltext bigrams",
    x = "Count",
    y = NULL
)
```

2.2) Consultar utilizando funciones de bibliometrix

2.2.1) Objetivo: realizar una consulta a la base de datos OpenAlex buscando recuperar los trabajos que contengan las palabras "deep learning" y "cyanobacteria"

```{r busqueda, echo=FALSE}
results <- search_openalex(query = "deep learning AND cyanobacteria")
```

Esta búsqueda devuelve un objeto de la clase data.frame con la siguiente información para cada 
artículo:

- ID: El identificador único del artículo.
- Titulo: El título del artículo.
- Autores: Los autores del artículo.
- Institución: La institución de los autores.
- Revista: La revista en la que se publicó el artículo.
- Año: El año de publicación del artículo.

2.2.2) Se puede calcular el número de artículos publicados por año:

```{r year_counts, echo=FALSE}
year_counts <- count_publications(results, by_year = TRUE)
```

Este cálculo devuelve un objeto de la clase data.frame con la siguiente información:

- Año: El año de publicación.
- Número de artículos: El número de artículos publicados en ese año.

2.2.3) Se puede calcular el número de artículos publicados por institución:

```{r institution_counts, echo=FALSE}
institution_counts <- count_publications(results, by_institution = TRUE)
```

Este cálculo devuelve un objeto de la clase data.frame con la siguiente información:

- Institución: La institución de los autores.
- Número de artículos: El número de artículos publicados por esa institución.


2.2.4) Se puede hacer un análisis bibliométrico completo, usando la función biblioAnalisys




# Conclusiones

Las técnicas presentadas en este informe permiten realizar un análisis exhaustivo del estado del arte de las investigaciones basadas en DL para el monitoreo, detección y alerta temprana de FC. Estas técnicas pueden ser utilizadas por investigadores, profesionales y otros interesados en este tema para obtener información sobre las tendencias actuales en la investigación, los principales grupos de investigación y las áreas de investigación emergentes.
